{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"P\u00e1gina inicial","text":"<p>meu github!</p> <p>Obrigado por logar</p>"},{"location":"A_modeling_guideline/A_overview/","title":"\ud83d\udcdd Overview","text":"<p>teste</p>"},{"location":"A_modeling_guideline/B_problem_understanding/","title":"\ud83c\udfaf Problem Understanding","text":""},{"location":"A_modeling_guideline/B_problem_understanding/#clarify-business-objective","title":"Clarify business objective","text":"<p>(e.g. reduce churn, predict default).</p>"},{"location":"A_modeling_guideline/B_problem_understanding/#define-the-target-variable","title":"Define the target variable","text":""},{"location":"A_modeling_guideline/B_problem_understanding/#classification","title":"Classification","text":""},{"location":"A_modeling_guideline/B_problem_understanding/#ever","title":"Ever","text":""},{"location":"A_modeling_guideline/B_problem_understanding/#over","title":"Over","text":""},{"location":"A_modeling_guideline/B_problem_understanding/#regression","title":"Regression","text":""},{"location":"A_modeling_guideline/B_problem_understanding/#identify-how-the-model-will-be-used-and-what-impact-it-should-have","title":"Identify how the model will be used and what impact it should have.","text":""},{"location":"A_modeling_guideline/C_data_preparation/","title":"\ud83d\udcca Data Understanding and Preparation","text":""},{"location":"A_modeling_guideline/C_data_preparation/#data-collection","title":"Data Collection","text":""},{"location":"A_modeling_guideline/C_data_preparation/#data-cleaning-and-preprocessing","title":"Data Cleaning and Preprocessing","text":""},{"location":"A_modeling_guideline/D_eda/","title":"\ud83d\udd0d Exploratory Data Analysis","text":"<p>a</p>"},{"location":"A_modeling_guideline/D_eda/#teste","title":"teste","text":""},{"location":"A_modeling_guideline/E_feature_engineering/","title":"\ud83d\udee0\ufe0f Feature Engineering","text":""},{"location":"A_modeling_guideline/E_feature_engineering/#feature-engineering","title":"Feature Engineering","text":""},{"location":"A_modeling_guideline/F_model_selection/","title":"\ud83c\udfb2 Model Selection","text":"<p>This is the design phase</p>"},{"location":"A_modeling_guideline/G_model_development/","title":"\ud83e\udde0 Model Development and Hyperparameter Tuning","text":""},{"location":"A_modeling_guideline/G_model_development/#tunning","title":"Tunning","text":""},{"location":"A_modeling_guideline/G_model_development/#evaluation","title":"Evaluation","text":""},{"location":"A_modeling_guideline/H_validation/","title":"\u2705 Model Validation and Evaluation","text":"<p>a</p>"},{"location":"A_modeling_guideline/I_model_interpretation/","title":"\ud83d\udca1 Model Interpretation and Explanability","text":"<p>a</p>"},{"location":"A_modeling_guideline/J_deployment/","title":"\ud83d\ude80 Deployment and Operationalization","text":"<p>a</p>"},{"location":"A_modeling_guideline/K_monitoring/","title":"\ud83d\udcc8 Model Monitoring and Maintenance","text":"<p>a</p>"},{"location":"A_modeling_guideline/L_governance/","title":"\u2696\ufe0f Governance, Ethical, and Regulatory Considerations","text":"<p>a</p>"},{"location":"A_modeling_guideline/M_tools/","title":"\ud83e\uddf0 Tools, Technologies, and Best Practices","text":"<p>a</p>"},{"location":"A_modeling_guideline/N_appendix/","title":"Appendix","text":""},{"location":"A_modeling_guideline/modeling_guideline/","title":"Introduction","text":"<p>Antes de iniciar esse direcionamento para Modelagem, lembre-se que todo modelo \u00e9 fruto de um trabalho artesanal, e esse material \u00e9 meramente um pilar para sua obra...</p> <p>Ap\u00f3s cada passo valide seu trabalho, caso n\u00e3o consiga validar todos, ao menos 10 casos para ter alguma ideia se o que est\u00e1 fazendo est\u00e1 caminhando da forma esperada.</p> <p>O conte\u00fado desse material foi desenvolvido pensando principalmente em modelos supervisionados, tendo espa\u00e7o para alguns insights sobre modelos n\u00e3o supervisionados.</p> <p>\u00c9 importante lembrarmos que independente do algoritmo que utilizarmos posteriormente, o maior ganho que teremos ser\u00e1 durante os primeiros passos da modelagem:</p> <ul> <li>na defini\u00e7\u00e3o de um target aderente ao problema que queremos solucionar</li> <li>na defini\u00e7\u00e3o de p\u00fablico eleg\u00edvel fiel ao nosso contexto real</li> <li>na cria\u00e7\u00e3o de features que, em conjunto, possam explicar melhor nosso modelo</li> <li>na sele\u00e7\u00e3o das melhores features para nosso contexto</li> <li>em m\u00e9todos eficazes e entendimento do neg\u00f3cio para definir o per\u00edodo a ser considerado na amostragem</li> </ul> <p>A utiliza\u00e7\u00e3o de algoritmos de ponta n\u00e3o ser\u00e1 nosso 'game change', ele pode nos garantir aquele ponto de m\u00e9trica a mais em nosso modelo, mas n\u00e3o ser\u00e1 o protagonista da modelagem.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#0-entendimento-do-problema","title":"0 - Entendimento do Problema","text":"<p>Antes de mais nada entenda seu problema e a necessidade da cria\u00e7\u00e3o de um modelo ou regra de neg\u00f3cio. Pode ser que seja necess\u00e1rio um modelo mais simples, que fique pronto em um menor tempo para gerar valor de forma mais r\u00e1pida, ou pode ser necess\u00e1rio um modelo mais complexo, que ir\u00e1 demandar um tempo maior. Pode ser tamb\u00e9m que para o problema n\u00e3o seja necess\u00e1rio um modelo, e sim um conjunto de regras de neg\u00f3cio a ser aplicado.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#1-definicao-do-target","title":"1 - Defini\u00e7\u00e3o do Target","text":"<p>Nesse momento, juntamente com a \u00e1rea de neg\u00f3cios temos que definir nosso objeto de estudo, juntamente com o que queremos modelar (target).</p> <p>Para a defini\u00e7\u00e3o do target devemos ter um tempo de observabilidade \u00e0 frente, a partir da nossa data de refer\u00eancia, para avaliar o comportamento desses clientes que ser\u00e3o utilizados para fomentar nosso modelo. No caso de trabalhar com modelos de target bin\u00e1rio a defini\u00e7\u00e3o de marca\u00e7\u00e3o a partir do EVER ou OVER vai depender da estrat\u00e9gia buscada. </p>"},{"location":"A_modeling_guideline/modeling_guideline/#ever-ou-over-qual-escolher","title":"Ever ou Over? Qual escolher?","text":"<p>O EVER ser\u00e1 mais conservador, enquanto o OVER ser\u00e1 mais liberal. No caso do EVER, o cliente que atrasa ee paga o juros, voltando a ficar adimplente \u00e9 considerado ruim, pois olhamos os atrasos at\u00e9 a janela final, enquanto para o OVER o cliente que atrasa e volta a pagar antes do final da janela \u00e9 considerado como bom pois olhamos apenas o retrato do final da janela. Para definir se ser\u00e1 usado um ou outro pode depender da forma que as bases da institui\u00e7\u00e3o s\u00e3o constru\u00eddas, por exemplo: clientes que renegociam contratos aparecem com novo contrato sem atraso, se olharmos o EVER teremos o atraso intram\u00eas do cliente, enquanto se olharmos o OVER n\u00e3o teremos a informa\u00e7\u00e3o que ele atrasou e vamos consider\u00e1-lo bom.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#ever","title":"Ever","text":"<pre><code>DT[, mob := min_dt_ref %--% dt_ref %/% months(1)] #define os mobs (a dt_ref minima pode ser a data de ativacao por exemplo no contexto de onboarding)\n\nDT &lt;-  DT[mob &gt;= 0 &amp; mob &lt;= 6 | is.na(mob)] #definido mob 6 caso se trate de um target ever60mob6, sendo essa a data m\u00e1xima avaliada. O NA est\u00e1 incluso em casos que n\u00e3o temos ativacao por exemplo ou clientes que n\u00e3o est\u00e3o na nossa tabela do CADOC\n\nDT_perf &lt;- DT[, .(fl_default = max(as.integer(atraso &gt;= 60)), ##flaga todos os meses em atraso ou n\u00e3o atraso e soma, caso o m\u00e1ximo seja 0 n\u00e3o temos default no intervalo\n             mob_default = min(mob[atraso&gt;=60]), #conta o n\u00famero de mobs, com o m\u00ednimo temos o m\u00eas em que o default ocorreu\n             qtd_meses_materialidade = sum(saldo_devedor&gt;50)), # n\u00fameros de meses que temos materialidade \n            .(cpf_cnpj, safra, qtd_mob)]\n</code></pre>"},{"location":"A_modeling_guideline/modeling_guideline/#over","title":"Over","text":"<pre><code>DT[, mob := min_dt_ref %--% dt_ref %/% months(1)] #define os mobs (a dt_ref minima pode ser a data de ativacao por exemplo no contexto de onboarding)\n\nDT &lt;-  DT[mob &gt;= 0 &amp; mob &lt;= 6 | is.na(mob)] #definido mob 6 caso se trate de um target ever60mob6, sendo essa a data m\u00e1xima avaliada. O NA est\u00e1 incluso em casos que n\u00e3o temos ativacao por exemplo ou clientes que n\u00e3o est\u00e3o na nossa tabela do CADOC\n\nDT_perf &lt;- DT[, .(fl_default = max(as.integer(atraso &gt;= 60)), ##flaga todos os meses em atraso ou n\u00e3o atraso e soma, caso o m\u00e1ximo seja 0 n\u00e3o temos default no intervalo\n             mob_default = min(mob[atraso&gt;=60]), #conta o n\u00famero de mobs, com o m\u00ednimo temos o m\u00eas em que o default ocorreu\n             qtd_meses_materialidade = sum(saldo_devedor&gt;50)), # n\u00fameros de meses que temos materialidade \n            .(cpf_cnpj, safra, qtd_mob)]\n</code></pre>"},{"location":"A_modeling_guideline/modeling_guideline/#definicao-de-bases","title":"Defini\u00e7\u00e3o de bases","text":"<p>Ap\u00f3s o target definido, deve ser feito um levantamento das bases que podem ser utilizadas para melhor explicar nosso target</p> <ul> <li>Dados internos</li> <li>Dados externos como SCR, Bureaus (Serasa, Quod, Boa vista, Belvo, Neurotech)</li> </ul>"},{"location":"A_modeling_guideline/modeling_guideline/#2-build-features","title":"2 - Build Features","text":"<p>A depender de cada caso a cria\u00e7\u00e3o de features pode ser antes ou depois da defini\u00e7\u00e3o do p\u00fablico eleg\u00edvel</p> <p>A partir do target definido, todo o escopo do projeto entendido, partimos para a cria\u00e7\u00e3o das features</p> <p>Para criarmos as features temos que nos atentar ao horizonte de feature que vamos utilizar. Podemos utilizar 3 meses de features, dessa forma pegamos a partir de uma data de refer\u00eancia, os tr\u00eas meses anteriores para montar nossas features.</p> <ul> <li>Uma op\u00e7\u00e3o \u00e9 juntar todas as bases cruas que ser\u00e3o utilizadas e posteriormente criar nossas features para evitar retrabalho e como melhor pr\u00e1tica</li> <li>Outra op\u00e7\u00e3o \u00e9 criar as features para cada base separadamente pois dessa maneira \u00e9 mais f\u00e1cil identificar poss\u00edveis problemas nas bases ou features criadas, essa op\u00e7\u00e3o se torna vi\u00e1vel quando n\u00e3o se tem dom\u00ednio ou confian\u00e7a suficiente sobre determinada base</li> </ul> <p>Podemos criar features utilizando diferentes horizontes de tempo para os clientes, por\u00e9m, para isso devemos ter alguma forma de identificar os clientes em que nosso tempo de features varia. Por exemplo: Se quisermos pegar como features o hist\u00f3rico de atraso de um cliente, devemos ter tamb\u00e9m uma feature com o tempo de contrato desse cliente, pois \u00e9 muito diferente um cliente que atrasou 2 parcelas em 2 meses com um cliente que atrasou 2 parcelas em 10 anos</p>"},{"location":"A_modeling_guideline/modeling_guideline/#21-publico-elegivel","title":"2.1 P\u00fablico Eleg\u00edvel","text":"<p>Avaliando, dentre toda nossa base, os clientes que possuem o horizonte definido de features, e as demais premissas necess\u00e1rias (hard filters, tempo de observabilidade para o target, etc), estes tornam-se nosso p\u00fablico eleg\u00edvel</p> <p>Tendo a base de features para o p\u00fablico eleg\u00edvel devemos valid\u00e1-la, para isso uma op\u00e7\u00e3o pode ser dividir sua base por meses e avaliar a volumetria por safra, aquelas que aparentarem inconsistentes, podemos dar um double check com uma query na determinada data, por exemplo.</p> <p>\u00c9 importante que a medida que seu p\u00fablico eleg\u00edvel vai se afunilando, voc\u00ea reporte os valores retirados em cada passo.</p> <p>Para a defini\u00e7\u00e3o do p\u00fablico eleg\u00edvel uma forma de tentar garantir a independ\u00eancia da sua base \u00e9 amostrando seu p\u00fablico. Quando voc\u00ea est\u00e1 em uma situa\u00e7\u00e3o em que n\u00e3o possui safra, ou seja, o mesmo cliente pode aparecer diversas vezes (collection, behavior, pre-creli) podemos criar janelas em que a mesma observa\u00e7\u00e3o n\u00e3o possa aparecer at\u00e9 o fim dessa janela, essa op\u00e7\u00e3o permite ainda amostrar dentro de cada m\u00eas para evitar que grande parte do p\u00fablico apare\u00e7a no primeiro m\u00eas e s\u00f3 possa aparecer novamente na pr\u00f3xima janela. Permitindo uma \"melhor aleatoriza\u00e7\u00e3o\" da nossa base.</p> <pre><code>DT_unique &lt;- unique(DT[atraso %in% (30:60)][order(dt_ref)])#aqui temos o p\u00fablico eleg\u00edvel que no caso s\u00e3o clientes com atraso entre 30 e 60\n# Fazer a amostragem ------------------------------------------------------\n\ndata &lt;- unique(DT_unique$dt_ref)\ndata &lt;- data[order(data)]\n\nset.seed(090815)\nall_obs &lt;- DT_unique[dt_ref == data[length(data)],\n                     slice_sample(.SD, n = min(.N, 150))\n] #pega ultimo mes dispon\u00edvel\n\n# Cria a amostragem para os outros meses\nfor ( i in (length(data)-1):1){\n  contrato_excluidos &lt;- all_obs[dt_ref &gt; data[i] &amp; dt_ref &lt; data[i] %m+% months(X), cd_contrato] \n  temp &lt;- base_3040_unique[dt_ref == data[i] &amp; !cd_contrato %in% contrato_excluidos,\n                           slice_sample(.SD, n = min(.N, 150))\n                           ]\n  all_obs &lt;- rbind(all_obs,temp)\n\n}#criamos uma janela do dia mais recente e pegando os meses anteriores respeitando nossa janela de X meses\n</code></pre> <p>Se em nossa situa\u00e7\u00e3o tivermos a safra do cliente (application, onboarding, acesso direto) basta encontrar uma forma de amostrar esses clientes olhando a safra de cada um e o n\u00famero de meses pra frente (para olhar o target) e para tr\u00e1s (para olhar as features) </p> <pre><code>\n</code></pre>"},{"location":"A_modeling_guideline/modeling_guideline/#3-analise-exploratoria-univariada-das-variaveis-de-interesse-features-inclusas","title":"3 - An\u00e1lise explorat\u00f3ria univariada das vari\u00e1veis de interesse (features inclusas)","text":"<p>Nesse momento a an\u00e1lise tem como objetivo encontrar outliers, semelhan\u00e7as na distribui\u00e7\u00e3o das features, etc</p> <ul> <li>Um ponto de aten\u00e7\u00e3o s\u00e3o as features com variabilidade pr\u00f3xima de 0, que talvez devam ser manipuladas ou at\u00e9 exclu\u00eddas.</li> <li>Remo\u00e7\u00e3o de features altamente correlacionadas</li> <li>Se o objetivo for a estima\u00e7\u00e3o utilizamos a base full, caso seu objetivo seja de predi\u00e7\u00e3o dividimos a base</li> <li>Esse passo pode tamb\u00e9m acontecer ap\u00f3s a an\u00e1lise bivariada, afim de conhecer melhor a base com features n\u00e3o significativas.</li> <li>Para evitar outliers, uma op\u00e7\u00e3o seria fixar os valores m\u00e1ximos e m\u00ednimos das features a partir dos percentis (alpha)% e (100-alpha)% por exemplo (outras a\u00e7\u00f5es podem ser tomadas, n\u00e3o existe f\u00f3rmula m\u00e1gica)</li> </ul> <p>Para sermos mais conservadores em rela\u00e7\u00e3o ao outliers podemos considerar <code>Outlier extremo</code>: Considerar valores menores que (Q1 - 3*dist AIQ) e maiores que (Q3 + 3*dist AIQ)</p>"},{"location":"A_modeling_guideline/modeling_guideline/#4-analises-bivariadas-para-validacao-das-features-pode-se-utilizar-decision-tree","title":"4 - An\u00e1lises bivariadas para valida\u00e7\u00e3o das features (pode-se utilizar decision tree)","text":"<p>Nesse momento a an\u00e1lise tem como objetivo observar se alguma feature vai de desencontro com nosso target, deixando um ponto de aten\u00e7\u00e3o.</p> <p>\u00c9 importante lembrar que na an\u00e1lise explorat\u00f3ria bivariada, comparando as features com o target, estamos cruzando as informa\u00e7\u00f5es das features com horizonte de X meses para tr\u00e1s, com o target definido com informa\u00e7\u00f5es X meses a frente.</p> <p>Nessa an\u00e1lise \u00e9 interessante observar se a distribui\u00e7\u00e3o das nossas vari\u00e1veis \u00e9 uniforme ao longo do tempo, para isso pode ser feita uma an\u00e1lise de drift m\u00eas a m\u00eas tanto utilizando PSI quanto Wasserstein. Uma outra maneira \u00e9 pegar algumas estat\u00edsticas(m\u00e9dia, mediana...) das vari\u00e1veis e observar se elas variam muito m\u00eas a m\u00eas ou fazer um teste <code>ks.test</code> para avaliar se ambas as amostras vem de uma mesma distribui\u00e7\u00e3o.</p> <p>Caso encontre uma aleatoriedade nas vari\u00e1veis m\u00eas a m\u00eas, dessa forma \u00e9 preciso tentar entender o porque de nossa popula\u00e7\u00e3o mudar tanto a cada safra. Vale uma reflex\u00e3o de caso houver uma cria\u00e7\u00e3o de janela para tentar garantir uma independ\u00eancia entre as observa\u00e7\u00f5es que queremos coletar (exemplo: criamos janelas com espa\u00e7amento de 6 meses em que o cliente s\u00f3 pode aparecer novamente no in\u00edcio da pr\u00f3xima janela para tentar garantir a independ\u00eancia das observa\u00e7\u00f5es que queremos coletar): Se criamos uma janela, o comportamento das nossas vari\u00e1veis pode n\u00e3o ficar bem representado safra a safra, dessa forma pode ser interessante reamostrar a base</p> <p>Essa an\u00e1lise safra a safra pode tamb\u00e9m ser feita na base de Treino, logo ap\u00f3s a separa\u00e7\u00e3o da base entre <code>treino</code>, <code>teste (Out of Sample)</code> e <code>homologa\u00e7\u00e3o (Out of Time)</code>, nesse caso olhamos primeiro a base de treino</p> <p>Na an\u00e1lise explorat\u00f3ria deve ter observado se m\u00eas a m\u00eas as vari\u00e1veis mantem um padr\u00e3o de comportamento</p> <pre><code>#observando a m\u00e9dia\ndist_variaveis &lt;- DT %&gt;% melt(id.vars = \"dt_ref\") %&gt;%\n  .[, mean(value), .(dt_ref, variable)] %&gt;%\n  dcast(dt_ref ~ variable)\n</code></pre> <p>O KS \u00e9 sens\u00edvel ao tamanho de sua amostra, ent\u00e3o amostras muito grandes rejeitam a hip\u00f3tese de igualdade entre a distribui\u00e7\u00e3o das vari\u00e1veis mais facilmente</p> <pre><code>#KS\nfeats &lt;- c(names(model$finalModel$coefficients)[-1])\ndrift &lt;- dados_treino %&gt;% dplyr::select(all_of(feats))\n\ndrift[,data_m0:=dados_treino$dt_mod]\n\nks_stat_drift &lt;- function(m0, var, d){\n  cat(as.character(m0), \":: \", var,\"\\n\")\n  m0 &lt;- ymd(floor_date(m0, unit = \"month\"))\n  mm1 &lt;- m0 %m-% months(1)\n  dm1 &lt;- d[floor_date(data_m0, unit = \"month\") == ymd(mm1), var,with=F] %&gt;% as.data.frame() # == para est\u00e1tico e &lt;= para acumulado\n  d0 &lt;- d[floor_date(data_m0, unit = \"month\") == m0, var, with=F] %&gt;% as.data.frame()\n  #print(paste(m0,'|',var))\n  ks &lt;- ks.test(dm1[,1],d0[,1])\n  z &lt;- t.test(dm1[,1],d0[,1])\n  return(list(var=var,\n              m0=m0,\n              ks_stat=ks$statistic,\n              ks_p_val=ks$`p.value`,\n              t=z$statistic,\n              t_p=z$`p.value`))\n}\n</code></pre> <p>Para diferenciar a m\u00e9trica est\u00e1tica da acumulada safra a safra, opta-se por utilizar <code>dm1</code> e <code>d0</code> com sinais, <code>==</code> para observar a rela\u00e7\u00e3o entre o m\u00eas e o anterior ou <code>&lt;=</code> para observar a rela\u00e7\u00e3o entre o m\u00eas com o acumulado dos demais meses.</p> <p>O Wasserstein mede o trabalho necess\u00e1rio para transformar uma distribui\u00e7\u00e3o em outra a partir dos valores reais das vari\u00e1veis, que podem variar muito e, consequentemente, deixar sua escala muito grande, por essa raz\u00e3o para utilizar o Wasserstein \u00e9 necess\u00e1rio escalar as features. O problema do Wasserstein se deve a falta de no\u00e7\u00e3o relacionado ao valor da escala, n\u00e3o \u00e9 poss\u00edvel saber se em uma escala que varia de 1 a 5, o valor 1 \u00e9 bom ou tudo de 1 a 5 \u00e9 ruim, por exemplo.</p> <pre><code>#Wasserstein\nfeats &lt;- c(names(model$finalModel$coefficients)[-1])\ndrift &lt;- dados_treino %&gt;% dplyr::select(all_of(feats))\n\ndrift[,data_m0:=dados_treino$dt_mod]\n\nwasser_stat_drift &lt;- function(m0,var,d){\n  m0 &lt;- ymd(floor_date(m0, unit = \"month\"))\n  mm1 &lt;- m0 %m-%months(1)\n  dm1 &lt;- d[floor_date(data_m0, unit = \"month\") == ymd(mm1), var, with=F] %&gt;% as.data.frame() # == ou &lt;=\n  d0 &lt;- d[floor_date(data_m0, unit = \"month\") == m0, var, with=F]%&gt;% as.data.frame() # == ou &lt;=\n  print(paste(m0,'|',var))\n  w &lt;- wasserstein1d(dm1[,1],d0[,1],p=1)\n  #z &lt;- t.test(dm1[,1],d0[,1])\n  return(data.frame(var=var,\n                    m0=m0,\n                    wasser=w\n                    #ks_p_val=ks$`p.value`,t=z$statistic,\n                    #t_p=z$`p.value`)\n  ))\n}\n\nfeats &lt;- append(feats, \"data_m0\")\ndados &lt;- base %&gt;% dplyr::select(all_of(feats)) %&gt;% mutate_if(is.numeric, scale) \n\n</code></pre> <p>O PSI assim como o Wasserstein n\u00e3o \u00e9 sens\u00edvel ao tamanho da amostra, por\u00e9m em seu processo s\u00e3o separadas as vari\u00e1veis em grupos e comparados, dessa forma o PSI \u00e9 sens\u00edvel ao n\u00famero de bins (grupos)</p> <pre><code>#PSI\nfeats &lt;- mf2$feature_names\n\ndrift &lt;- treino3 %&gt;% select(any_of(feats))\n\ndrift[,data_m0:=treino3$data_m0]\ndrift[,m0:=NULL]\n\nks_stat_drift &lt;- function(m0,var,d){\n  m0 &lt;- ymd(floor_date(m0, unit = \"month\"))\n  mm1 &lt;- m0 %m-% months(1)\n  dm1 &lt;- d[floor_date(data_m0, unit = \"month\") &lt;= mm1,var,with=F] %&gt;% as.data.frame()\n  d0 &lt;- d[floor_date(data_m0, unit = \"month\") == m0,var,with=F]%&gt;% as.data.frame()\n  #print(paste(m0,'|',var))\n  ks &lt;- ks.test(dm1[,1],d0[,1])\n  z &lt;- t.test(dm1[,1],d0[,1])\n  dm1$m &lt;- mm1\n  d0$m &lt;- m0\n  psi &lt;- get_psi(dat=rbind(dm1,d0),occur_time='m')\n  return(data.frame(var=var,m0=m0,ks_stat=ks$statistic,ks_p_val=ks$`p.value`,t=z$statistic,\n         t_p=z$`p.value`,psi=psi[,unique(PSI)]))\n\n}\n</code></pre> <p>Ap\u00f3s escolher qual fun\u00e7\u00e3o utilizar \u00e9 necess\u00e1rio rodar o <code>map</code> e posteriormente o ggplot caso queira visualizar o gr\u00e1fico do drift</p> <pre><code>x &lt;- map2_dfr(.x = rep(seq.Date(ymd('2018-05-01'), #primeiro mes da sua base +1\n                                ymd('2022-06-01'), #\u00faltimo mes da sua base\n                                by = 'month'),\n                       each = 17), #quantidade de vari\u00e1veis\n              .y = rep(names(drift), 50), #quantidade de meses entre o in\u00edcio e fim das datas\n              .f = ~ ks_stat_drift(.x, .y, base)) %&gt;% setDT()\n\nx[, sig:=as.integer(ks_p_val&lt;=0.05)]\n\nx2 &lt;- data.table::dcast(x,var~m0,value.var = 'ks_stat')\n\n#fun\u00e7\u00e3o para plotar o gr\u00e1fico\nggplot(x,aes(x=m0,y=var,fill=ks_stat))+\n  geom_tile(width=50,col='white')+\n  scale_x_date(date_labels = \"%m/%Y\",date_breaks = \"29 day\",expand = c(0,0))+\n  # scale_x_date(expand = c(0,0))+\n  labs(x=\"\",y=\"\",title = \"Drift ao longo do tempo - Wasserstein m\u00eas anterior\",\n       fill = \"\")+\n  theme_minimal()+\n  scale_fill_distiller(type='div')+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n</code></pre>"},{"location":"A_modeling_guideline/modeling_guideline/#5-regression","title":"5 - Regression","text":"<p>A regress\u00e3o, por sua simplicidade, deve ser sempre a primeira escolha na hora de criar seu modelo baseline. Ap\u00f3s um primeiro teste podemos partir para outros modelos mais robustos.</p> <ul> <li> <p>Devemos interpretar os coeficientes e suas dire\u00e7\u00f5es e ver se fazem sentido para o contexto estudado</p> </li> <li> <p>Escalar as vari\u00e1veis e retreinar o modelo. Como a regress\u00e3o log\u00edstica \u00e9 muito sens\u00edvel a outliers coisas muito estranhas, como KS variando muito safra a safra ou coeficiente que esperasse ser significativo n\u00e3o sendo, podem ser explicados por n\u00e3o escalar as vari\u00e1veis.</p> </li> </ul> <p>Em alguns casos ter o trabalho de escalar as vari\u00e1veis pode ser em v\u00e3o, como por exemplo em casos que temos padr\u00f5es muito diferentes de nossas features safra a safra, com comportamentos completamente aleat\u00f3rios para uma mesma vari\u00e1vel.</p> <p>Uma alternativa para a regress\u00e3o linear, por exemplo, em que as vari\u00e1veis n\u00e3o s\u00e3o significativas, \u00e9 utilizar <code>GAMs</code> para testar se as vari\u00e1veis tem uma rela\u00e7\u00e3o n\u00e3o linear, de maneira simples.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#51-machine-learning","title":"5.1 - Machine Learning","text":"<p>Outra possibilidade \u00e9 utilizar modelos mais robustos como por exemplo XGBoost, que nada mais \u00e9 que um conjunto de \u00e1rvores, com seus par\u00e2metros bem tunados ou LightGBM que \u00e9 uma vers\u00e3o mais r\u00e1pida do XGBoost.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#tunando-parametros","title":"Tunando par\u00e2metros","text":"<p>Esse passo \u00e9 essencial para encontrar qual o melhor conjunto de par\u00e2metros para obter uma melhor performance para seu modelo</p> <pre><code>tune_grid_xgb&lt;- expand.grid(\n    nrounds= c(50,100),\n    eta = c(0.02, 0.01), #taxa de aprendizado, quanto menor, menor a chance de overfitting\n    gamma = c(1), #quanto maior mais conservador o algoritmo [0,infinito]\n    max_depth = 4:6, #profundidade da \u00e1rvore(complexidade) de [0,infinito] sendo 0 sem limita\u00e7\u00e3o de profundidade\n    min_child_weight = c(5),\n    subsample= c(0.5),#propor\u00e7\u00e3o de subamostra de treinamento, 50% dos dados de treino ser\u00e3o amostrados antes da cria\u00e7\u00e3o das arvores\n    colsample_bytree=0.2 #propor\u00e7\u00e3o das vari\u00e1veis escolhidas aleatoriamente para contruir cada \u00e1rvore\n  )\n</code></pre>"},{"location":"A_modeling_guideline/modeling_guideline/#interpretacao","title":"Interpreta\u00e7\u00e3o","text":"<p>Em modelos mais robustos, assim como na regress\u00e3o, existe a necessidade de interpreta\u00e7\u00e3o. Enquanto em um basta interpretar os coeficientes e observar se o sentido de cada um faz sentido para o contexto estudado, para esses modelos \"Black Box\" temos o SHAP(SHapley Additive exPlanations) para permitir a interpretabilidade das vari\u00e1veis. Utilizando o SHAP na nossa base de treino conseguimos tirar insights sobre o que o modelo aprender com cada uma das vari\u00e1veis dispostas.</p> <p>Para utilizar o SHAP, caso estejamos com um modelo xgboost precisamos primeiro trasformar nossa base em uma matriz para posteriormente utilizarmos a fun\u00e7\u00e3o, como podemos ver abaixo:</p> <pre><code>pred_data &lt;- model.matrix(.outcome~., model$trainingData)[,-1]#passando uma matriz(caso o modelo seja um xgboost)\nexplain(model$finalModel, exact = TRUE, newdata = pred_data) %&gt;% setDT() #fun\u00e7\u00e3o para retornar shap value, caso o modelo seja um xgboost \u00e9 necess\u00e1rio passar uma matriz\n\n</code></pre> <p>Ap\u00f3s a an\u00e1lise do SHAP, caso tenha muitas features, na hora de apresentar a relev\u00e2ncia das vari\u00e1veis pode ser interessante utilizar o detalhamento de Pareto para mostrar apenas os \"20% de features que explicam 80% do modelo\"</p>"},{"location":"A_modeling_guideline/modeling_guideline/#6-modelagem","title":"6 - Modelagem","text":""},{"location":"A_modeling_guideline/modeling_guideline/#splitting","title":"Splitting","text":"<ul> <li> <p>Dividir nossa base em treino, teste (Out of Sample) e homologa\u00e7\u00e3o (Out Of Time)</p> </li> <li> <p>Homologa\u00e7\u00e3o (OOT): pegamos os meses mais recentes para conseguirmos uma valida\u00e7\u00e3o mais quente da performance do nosso modelo. A homologa\u00e7\u00e3o s\u00f3 pode ser testada uma \u00fanica vez, ap\u00f3s todo o tr\u00e2mite com a base de treino e teste. Utilizar a base de homologa\u00e7\u00e3o mais de uma vez \u00e9 incorreto pois voc\u00ea estar\u00e1 balizando seu resultado mais recente para definir se seu modelo est\u00e1 bom ou n\u00e3o, quando na verdade ele deve servir apenas para validar se o que foi feito com o treino e teste estava bom. Via de regra, se tudo estiver ok com o treino/teste a homologa\u00e7\u00e3o ser\u00e1 um reflexo disso. O que n\u00e3o siginifca que caso o OOT estiveja ruim, tenhamos necessariamente um problema como o modelo, pode ser que a popula\u00e7\u00e3o de treino j\u00e1 n\u00e3o \u00e9 mais reflexo da popula\u00e7\u00e3o atual, ou que tenhamos uma sazonalidade no per\u00edodo do OOT analisado, ou que existam padr\u00f5es temporais que n\u00e3o conseguimos captar como o modelo, ou que passou despercebido pelo analista.</p> </li> </ul> <p>Do restante da base dividimos em 2 grupos seguindo a l\u00f3gico do 70/30 ou outras, como por exemplo considerar um erro fixo para treino e teste e a partir dai definir o tamanho ideal das amostras</p> <ul> <li>Treino: selecionando 70% da base restante</li> <li>Teste: selecionando 30% da base restante</li> </ul> <pre><code>#Op\u00e7\u00e3o 1\nsplit_test &lt;- function(z = 1.96, e = 0.025, sd = 0.5){\n  n_teste = ((z*sd)/e)^2\n  n_teste\n} #fun\u00e7\u00e3o para encontrar o tamanho da amostra de teste fixando o erro do treino e teste\n#depende indiretamente do tamanho da base pois e = z*(sigma/sqrt(n))\n\n#Op\u00e7\u00e3o 2\nsplit_test &lt;- function(base){\n  n &lt;- nrow(base) #tamanho populacao\n  z &lt;- 1.96 #z-score\n  e &lt;- 0.025#margem de erro\n  sd &lt;- 0.5 #desvio padr\u00e3o\n\n  (((z^2)*sd*(1-sd))/e^2)/1+(((z^2)*sd*(1-sd))/(e^2)/n)\n}#fun\u00e7\u00e3o para encontrar o tamanho da amostra de teste fixando o erro do treino e teste\n\n</code></pre> <p>Ap\u00f3s a separa\u00e7\u00e3o das amostras devemos fazer um teste PSI (Population Stability Index) para avaliar se nossa Homologa\u00e7\u00e3o, Treino e Teste est\u00e3o semelhantes. Como no OOT n\u00e3o existe amostragem pode ser que ele se distingua muito da sua base de treino e teste. Bastaria fazer a compara\u00e7\u00e3o de Homologa\u00e7\u00e3o com o Treino ou o Teste, por\u00e9m, para uma maior certeza da aleatoriedade da fun\u00e7\u00e3o do R fazemos a compara\u00e7\u00e3o tanto com o Treino quanto com o Teste apenas como um double check.</p> <p>Para testar o PSI podemos utilizar pacotes como <code>creditmodel</code> e <code>PDtoolkit</code></p> <p>Al\u00e9m do PSI \u00e9 interessante fazer uma an\u00e1lise de drift para avaliar se features das amostras de treino, teste e homologa\u00e7\u00e3o est\u00e3o bem representadas.</p> <p>Na an\u00e1lise explorat\u00f3ria deve ter observado se m\u00eas a m\u00eas as vari\u00e1veis mantem um padr\u00e3o de comportamento</p> <p>De in\u00edcio, testamos um modelo mais simples para avaliar a performance do nosso baseline, em um segundo momento vale a pena compararmos a performance do Random Forest, XGboost, dentre diversos outros poss\u00edveis.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#modeling","title":"Modeling","text":""},{"location":"A_modeling_guideline/modeling_guideline/#full-model","title":"Full model","text":"<p>Primeiro devemos transformar nosso target em fator e em seguida podemos rodar um primeiro modelo com todas as vari\u00e1veis (modelo full).</p> <p>Ap\u00f3s cada passo a seguir podemos rodar um modelo para ir acompanhando a performance do modelo atrav\u00e9s do KS</p> <p>Utilizamos a fun\u00e7\u00e3o abaixo para retornar um vetor com a probabilidade de cada vari\u00e1vel ser considerada 1 no nosso target</p> <pre><code>probabilities &lt;- model %&gt;% predict(teste, type = \"response\")\n</code></pre> <p>Caso possua um valor de refer\u00eancia para avaliar a precis\u00e3o do modelo (por exemplo 0.8), o c\u00f3digo abaixo pode ser \u00fatil</p> <pre><code>### predi\u00e7\u00e3o ----\npredicted.classes &lt;- ifelse(probabilities &gt; 0.8, \"PG\", \"NPG\")\n# precisao do modelo\nmean(predicted.classes == teste$fl_good)\n</code></pre> <p>Para calcular o KS da base de treino utilizamos:</p> <pre><code>### KS treino ----\nsetDT(treino)\ntreino[, fl_good := ifelse(target == \"NPG\", 0, 1)]#transformando seu target em num\u00e9rico para medir o KS\nMLmetrics::KS_Stat(y_pred = model$fitted.values, y_true = treino$target)\n</code></pre> <p>Para calcular o KS da base de teste utilizamos:</p> <pre><code>### KS teste ----\nsetDT(teste)\nteste[, target := ifelse(target == \"NPG\", 0, 1)]#transformando seu target em num\u00e9rico para medir o KS\nMLmetrics::KS_Stat(y_pred = probabilities, y_true = teste$target)\n\n</code></pre> <p>Ap\u00f3s calcular o KS vai ser interessante olhar a curva ROC e o valor do AUC e PRAUC que seu modelo retorna.</p> <ul> <li>Vale resaltar que o AUC independe de escala pois n\u00e3o utiliza valores absolutos e sim a precis\u00e3o das classifica\u00e7\u00f5es</li> <li>O AUC n\u00e3o \u00e9 uma boa m\u00e9trica para se observado em uma base desbalanceada, pois como avalia apenas a taxa de verdadeiro positivo e falso positivo ela facilmente conseguir\u00e1 um alto AUC caso tenha muitos TRUE e baixo caso tenha muitos FALSE</li> <li>O PRAUC \u00e9 utilizado em bases desbalanceadas</li> </ul> <p>Precision: $\\frac{True Positive}{True Positive + False Positive}$   Recall: $\\frac{True Positive}{True Positive + False Negative}$</p> <p>Bases desbalanceadas facilmente conseguem um AUC alto</p> <pre><code>roc1=plot.roc(treino$target,fitted(model))\n\nplot(roc1,\n     print.auc=TRUE,\n     auc.polygon=TRUE,\n     grud=c(0.1,0.2),\n     max.auc.polygon=TRUE,\n     auc.polygon.col=\"#ff7a00\",\n     print.thres=TRUE)\n</code></pre>"},{"location":"A_modeling_guideline/modeling_guideline/#filtered-models","title":"Filtered models","text":""},{"location":"A_modeling_guideline/modeling_guideline/#without-zerovar-features","title":"without ZeroVar features","text":"<p>Em seguida podemos avaliar se temos vari\u00e1veis sem vari\u00e2ncia utilizando <code>nearZeroVar(DT,freqCut=98/2, saveMetrics= TRUE)</code> e rodar um novo modelo seguindo os passos de modelagem anteriores. A cada novo passo adicione as vari\u00e1veis que v\u00e3o sair do seu modelo em um vetor <code>cols_ignore &lt;- append(cols_ignore, rownames(var_nearzerovar)[var_nearzerovar$nzv])</code></p>"},{"location":"A_modeling_guideline/modeling_guideline/#with-little-correlation","title":"with little correlation","text":"<p>Depois de avaliar se temos vari\u00e1veis sem vari\u00e2ncia podemos buscar por correla\u00e7\u00e3o entre as restantes com <code>findCorrelation(DT %&gt;% select_if(is.numeric) %&gt;% cor(), cutoff = .75)</code></p> <p>Note que utilizamos apenas vari\u00e1veis num\u00e9ricas pois para outras vari\u00e1veis n\u00e3o faz sentido olhar correla\u00e7\u00e3o dessa forma</p> <p>Adicione as novas vari\u00e1veis no seu vetor de vari\u00e1veis a serem ignoradas <code>cols_ignore &lt;- append(cols_ignore, var_corr)</code> e rode um novo modelo para continuar acompanhando o desempenho do modelo com o <code>MLmetrics::KS_Stat(y_pred = probabilities, y_true = teste$target)</code></p>"},{"location":"A_modeling_guideline/modeling_guideline/#with-little-vif","title":"with little VIF","text":"<p>Para esse passo retiramos vari\u00e1veis que tenham um VIF alto, na literatura VIF &gt; 5 \u00e9 considerado alto, por\u00e9m para sermos mais conservadores podemos considerar VIF &gt; 10. Esse passo serve como um double-check da an\u00e1lise de correla\u00e7\u00e3o feita anteriormente, para garantir que as vari\u00e1veis n\u00e3o est\u00e3o correlacionadas, ent\u00e3o \u00e9 bem comum que nesse passo n\u00e3o encontre vari\u00e1veis para serem retiradas caso tenha considerado um cut razo\u00e1vel para seu findCorrelation (\\&lt; 0.7 por exemplo)</p> <pre><code>vif_model &lt;- vif(model)\nvif_model &lt;- as.data.frame(vif(model))\ncols_ignore &lt;- append(cols_ignore, rownames(vif_model)[vif_model &gt; 10])\n</code></pre>"},{"location":"A_modeling_guideline/modeling_guideline/#value-of-the-information","title":"Value of the Information","text":""},{"location":"A_modeling_guideline/modeling_guideline/#information-value","title":"Information Value","text":"<p>Ap\u00f3s os passos anteriores, rodamos um Information Value afim de observar se existe alguma rela\u00e7\u00e3o linear univariada entre alguma feature e o target.</p> <p>No caso em que voc\u00ea tenha muitas features e o calculo da correla\u00e7\u00e3o estiver demorando muito, \u00e9 poss\u00edvel utilizar o Information Value com um valor baixo (0.02 por exemplo) antes do calculo da correla\u00e7\u00e3o. Mesmo que ele far\u00e1 a an\u00e1lise univariada, e dessa forma j\u00e1 reduzir\u00e1 dimensionalidade do seu banco total para na hora de rodar a correla\u00e7\u00e3o tenhamos menos vari\u00e1veis e o processo seja menos custoso.</p> <p>Rules related from Siddiqi (2006)</p> <p>Not useful for prediction: &lt; 0.02 Weak predictive Power: 0.02 to 0.1 Medium predictive Power: 0.1 to 0.3 Strong predictive Power: 0.3 to 0.5 Suspicious Predictive Power &gt; 0.5</p> <p>Limita\u00e7\u00f5es:</p> <ul> <li>O IV assume uma rela\u00e7\u00e3o linear entre as categorias, dessa forma caso essa rela\u00e7\u00e3o n\u00e3o seja linear a import\u00e2ncia da vari\u00e1vel estar\u00e1 incorretamente calculada.</li> <li>N\u00e3o considera correla\u00e7\u00e3o: O IV trata cada vari\u00e1vel individualmente, n\u00e3o considerando poss\u00edveis itera\u00e7\u00f5es entre vari\u00e1veis. Dessa for, n\u00e3o captura totalmente a complexidade a qual v\u00e1rias vari\u00e1veis podem influenciar o resultado desejado em conjunto.</li> <li>\u00c9 sens\u00edvel ao n\u00famero de <code>bins</code>, pois categorias com baixa volumetria podem n\u00e3o ser significativamente grande para termos uma propor\u00e7\u00e3o real de bons e maus</li> <li>\u00c9 mais apropriado o uso em contextos de classifica\u00e7\u00e3o bin\u00e1ria</li> </ul> <pre><code>IV &lt;- Information::create_infotables(data = DT[, c(vars, 'target'), with = F], y = 'target')$Summary %&gt;% setDT()\n</code></pre> <p>$$WOE = ln(Good Distribution / Bad Distribuition)$$</p> <p>$$IV = \\sum(Good Distribution - BadDistribution)*WOE$$</p> <p>WOE avalia o poder de previs\u00e3o de uma categoria em rela\u00e7\u00e3o a outra. Se uma categoria apresenta um valor alto de WOE significa que a categoria distingue eficientemente os eventos dos n\u00e3o eventos</p>"},{"location":"A_modeling_guideline/modeling_guideline/#mutual-information","title":"Mutual Information","text":"<p>Ap\u00f3s os passos anteriores, rodamos um Mutual Information afim de observar se existe alguma rela\u00e7\u00e3o n\u00e3o linear entre alguma feature e nosso target.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#stepwise","title":"Stepwise","text":"<p>Utilizar caso precise avaliar o melhor conjunto de features para sua modelagem.</p> <pre><code>RcmdrMisc::stepwise(model, direction = 'backward/forward', criterion = 'BIC')\n</code></pre>"},{"location":"A_modeling_guideline/modeling_guideline/#feature-selection-methods","title":"Feature Selection Methods","text":"<p>Nessa etapa final de Feature Engineering podemos utilizar m\u00e9todos como <code>Boruta</code>, <code>infgain</code>, <code>mrmr</code>, dentre outros, para um passo extra de sele\u00e7\u00e3o de features.</p> <ul> <li>Boruta: cria uma vari\u00e1vel aleat\u00f3ria e desconsidera todas as existentes que explicarem menos que a vari\u00e1vel aleat\u00f3ria gerada.</li> <li>InfGain: entropy of the class distribution before and after the split resultando em algo entre 0 (sem ganho) e 1 (ganho m\u00e1ximo)</li> <li> <p>mrmr: maximum Relevancy Minimum Redundancy</p> </li> <li> <p>Lasso</p> </li> </ul> <pre><code>Boruta::Boruta(DT, target~.)\n</code></pre>"},{"location":"A_modeling_guideline/modeling_guideline/#teste-hosmer-e-lemeshow","title":"Teste Hosmer e Lemeshow","text":"<p>Utilizamos o teste de Hosmer e Lemeshow (Teste Qui-quadrado) para demonstrar a qualidade do ajuste de nosso modelo de regress\u00e3o log\u00edstica, ou seja, se o modelo pode explicar os dados observados. A hip\u00f3tese nula do teste \u00e9 a de as propor\u00e7\u00f5es observadas e esperadas serem as mesmas ao longo da amostra (alto poder preditiva)</p> <p>$$H_0$: $Prop_{o_i}$ = $Prop_{e_i}$$</p> <pre><code>hl = ResourceSelection::hoslem.test(treino$target,fitted(modelo), g = 10)\n</code></pre>"},{"location":"A_modeling_guideline/modeling_guideline/#matriz-de-confusao","title":"Matriz de Confus\u00e3o","text":"<p>A matriz de confus\u00e3o te retornar\u00e1 a Sensibilidade, Especificidade, dentre outros indicadores para avaliar a acertividade do seu modelo</p> <p>Para a cria\u00e7\u00e3o dessa matriz, temos que sugerir um ponto de corte, por exemplo, no caso de uma modelagem de pagamento temos que definir um ponto de corte em que dizemos se aquele cliente vai ou n\u00e3o nos pagar. Vimos isso no t\u00f3pico de modelagem para medir a precis\u00e3o do modelo. Nesse contexto agora, n\u00e3o temos esse valor de refer\u00eancia, ent\u00e3o queremos encontr\u00e1-lo, e para isso temos algumas possibilidades:</p> <p>1- Olhar o ponto de corte do KS para o score</p> <pre><code>pred &lt;- ROCR::prediction(predictions = dados_teste$pred, labels = dados_teste$true)\nperf &lt;- ROCR::performance(pred, \"tpr\", \"fpr\")\nTPR &lt;- unlist(perf@y.values)\nFPR &lt;- unlist(perf@x.values)\ndiff_TPRFPR &lt;- TPR - FPR\nmax(diff_TPRFPR)#KS\ncutoffAtKS &lt;- unlist(perf@alpha.values)[which.max(diff_TPRFPR)][]#corte do Score\n</code></pre> <p>2 - Olhar qual ponto de corte maximiza o F1</p> <pre><code>\n</code></pre> <p>3 - Olhar o ponto de inflex\u00e3o da curva ROC</p> <pre><code>\n</code></pre> <p>Como ambos (KS e F1) s\u00e3o medidas de qualidade geral do modelo, esperasse que os valores encontrados para cada um estejam pr\u00f3ximos</p>"},{"location":"A_modeling_guideline/modeling_guideline/#ks","title":"KS","text":"<p>Um KS muito alto \u00e9 um ponto de aten\u00e7\u00e3o, pode ser que uma vari\u00e1vel foi coletada incorretamente, existe alguma vari\u00e1vel correlacionada com sua resposta, dentre outros. Por exemplo, um KS de 60 em um contexto real, utilizando uma regress\u00e3o \u00e9 algo para se colocar em alerta.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#ks-por-safra","title":"KS por safra","text":"<p>Avaliar o KS por safras para avaliar o desempenho do seu modelo safra a safra. Caso utilize m\u00eas a m\u00eas e sua volumetria seja baixa, seu KS pode ficar bastante vol\u00e1til. Uma maneira de validar essa hip\u00f3tese \u00e9 olhar a distribui\u00e7\u00e3o do KS em intervalos de tempo maiores para aumentar a volumetria, por exemplo bimestral ou semestralmente.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#intervalo-de-confianca-para-o-ks","title":"Intervalo de Confian\u00e7a para o KS","text":"<p>Rodar um bootstrap para calcular o intervalo de confian\u00e7a do nosso KS. Calcular tamb\u00e9m o IC do KS safra a safra, para observarmos se os limites s\u00e3o respeitados.</p> <pre><code>IC_KS = function(data, B, safra){\n  ks_interv &lt;- map_dbl(1:B,~{\n    idx &lt;- sample(dim(data)[1],replace = T)\n    bd &lt;- data[idx]\n    inter.ai::ks_calc(bd[dt_ref == safra, pred],bd[dt_ref == safra, fl_good])\n  }, .progress = TRUE\n  )\n  summary(ks_interv)\n  hist(ks_interv, probability = TRUE)\n  quantile(ks_interv,c(.025,.975))\n}#fun\u00e7\u00e3o retorna o IC do KS do seu modelo a partir de um bootstrap\n#pega a media (ou mediana por a distribui\u00e7\u00e3o do KS ser sim\u00e9trica)\n\nic_ks_safra &lt;- map_dfr(.x = seq.Date(ymd('2018-04-01'),\n                                     ymd('2018-07-01'),\n                                     by = 'months'),\n                       .f = ~ IC_KS(safra = .x, B = 5000, data = treino)) %&gt;% setDT()#fun\u00e7\u00e3o retorna KS safra a safra\n\n</code></pre>"},{"location":"A_modeling_guideline/modeling_guideline/#modelo-aleatorio","title":"Modelo Aleat\u00f3rio","text":"<p>Pode acontecer de o modelo estar aparentemente bom, por\u00e9m temos apenas uma correla\u00e7\u00e3o esp\u00faria entre nossas vari\u00e1veis, para isso podemos utilizar um bootstrap (caso nossa amostra seja pequena) e rodar um modelo somente com intercepto e <code>rnorm</code> e avaliar o KS desse modelo safra a safra. Esse modelo necessariamente deve ser ruim, pois uma vari\u00e1vel completamente aleat\u00f3ria n\u00e3o pode explicar bem seu modelo.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#oversampling","title":"Oversampling","text":"<p>Para caso de baixa volumetria, uma tentativa v\u00e1lida \u00e9 utilizar a t\u00e9cnica de Oversampling para aumentar sua amostragem. (Existem muitas cr\u00edticas a essa metodologia, vale a pena estudar mais sobre o assunto)</p> <p>A aus\u00eancia de informa\u00e7\u00e3o tamb\u00e9m \u00e9 informa\u00e7\u00e3o. Treinar um modelo que seja desbalanceado \u00e9 ser fided\u00edgno a realidade do seu problema.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#cross-validate","title":"Cross-Validate","text":"<p>Se estiver cogitando utilizar CV deveria responder tr\u00eas perguntas:</p> <ul> <li>What problem am I trying to solve by using k-fold cross validation?</li> <li>How will I know if k-fold cross validation has solved that problem?</li> <li>Will a different approach be more effective at solving my problem?</li> </ul> <p>Caso algum fold tenha uma discrep\u00e2ncia no KS \u00e9 sinal que temos problemas na base. Um valor baixa de kappa tamb\u00e9m \u00e9 um forte ind\u00edcio que o modelo n\u00e3o est\u00e1 bom.</p> <p>Algo interessante a se observar \u00e9 a compara\u00e7\u00e3o entre o <code>model$pred</code> e o <code>predict(model, type = \"prob)</code> quando se utiliza o m\u00e9todo de cross-validate em seu modelo no caret. Esses valores v\u00e3o ser diferentes pois com o cross-validate temos uma base de treino um pouco diferente da base original.</p> <p>Caso seu modelo esteja com overfitting voc\u00ea ter\u00e1 um valor muito discrepante entre ambos, mas caso os valores estejam pr\u00f3ximos n\u00e3o significa que n\u00e3o temos overfitting</p> <p>Em um contexto geral ap\u00f3s dividir sua base em treino e teste utiliza o CV em sua base de treino para tunar seus hiperpar\u00e2metros, de modo que internamente sua base de treino ser\u00e1 redividida em treino e teste na propor\u00e7\u00e3o de <code>100 - (100/k-folds)</code> para treino e <code>100/k-folds</code> para teste <code>k-folds</code> vezes, definindo entre os <code>k-folds</code> cen\u00e1rios testados qual teve as melhores estimativas de desempenho com maior grau de precis\u00e3o. O benef\u00edcio de utilizar esse m\u00e9todo \u00e9 reduzir a varia\u00e7\u00e3o de nossa estimativa para desempenho fora da amostra (base de treino), n\u00e3o de fato melhorando nosso modelo. Posteriormente ao aplicar o melhor conjunto de hiperpar\u00e2metros para nossa base de teste original n\u00e3o estaremos tendo um problema de overfitting, pois a nossa base de teste n\u00e3o foi utilizada para essa defini\u00e7\u00e3o.</p> <p>Se temos por exemplo 5 folds, a valida\u00e7\u00e3o cruzada pelo caret ir\u00e1 selecionar o fold com os melhores hiperpar\u00e2metros e aplicar na base original de treino. Uma alternativa a se pensar seria utilizar como base de treino o modelo treinado pelo melhor fold, dessa forma podendo dar um perdict no que antes era sua base original de treino, utilizando o predict de teste interno dos demais 4 folds como insumo para a \u00e1rea ne neg\u00f3cio. Dessa forma seria poss\u00edvel dar um predict na base que originariamente era de treino para enviar a \u00e1rea de neg\u00f3cios, diferentemente de se tivessemos treinado o modelo com a base original de treino. \u00c9 importante lembrar que dar um predict na abse que voc\u00ea utilizou para treinar seu modelo resultar\u00e1 em dados excessivamente otimistas que dificilmente ser\u00e3o generalizados para novos dados</p> <p>O Nested Cross Validate \u00e9 utilizado quando originalmente n\u00e3o \u00e9 separada a base em treino e teste, pois internamente j\u00e1 ser\u00e1 separada em treino, teste e valida\u00e7\u00e3o e ser\u00e3o testados os hiperpar\u00e2metros da mesma forma que vimos anteriormente</p> <pre><code># WIP - codigo nao roda e n\u00e3o foi validado\nset.seed(998)\n\nfolds &lt;- createMultiFolds(iris$Species, k = 5, times = 2) ## 2 rep 5-fold CV for performance evaluation\n\ninner_res &lt;- trainControl(method = \"cv\", number = 5) ## 5-fold CV for hyperparameter tuning\n\nmod_list &lt;- lapply(folds, function(x) { # train models for each of the 10 training sets\n  train(Species ~ ., data = iris[x,], \n        method = \"rf\", \n        trControl = inner_res,\n        verbose = FALSE)\n})\n\npred_list &lt;- mapply(function(x, y) { # compute predictions on each of the 100 test sets\n  predict(x, iris[-y,])}, \n  x = mod_list, y = folds)\n\nperf_sens_spec_list &lt;- mapply(function(x, y) { # calculate performance measures I\n  confusionMatrix(x, iris[-y, \"Species\", drop = TRUE])$byClass[c(1,2)]}, \n  x = pred_list, y = folds)\n\nperf_accuracy_kappa_list &lt;- mapply(function(x, y) { # calculate performance measures II\n  confusionMatrix(x, iris[-y, \"Species\", drop = TRUE])$overall[c(1,2)]}, \n  x = pred_list, y = folds)\n\n# average performance across the 100 test sets\nmean(perf_sens_spec_list[\"Sensitivity\", ])\nmean(perf_sens_spec_list[\"Specificity\", ])\nmean(perf_accuracy_kappa_list[\"Accuracy\", ])\nmean(perf_accuracy_kappa_list[\"Kappa\", ])\n</code></pre>"},{"location":"A_modeling_guideline/modeling_guideline/#importancia-e-comportamento-da-feature","title":"Import\u00e2ncia e Comportamento da feature","text":"<p>Um ponto interessante de se observar \u00e9 a import\u00e2ncia que a feature tem no seu modelo. Quando estamos trabalhando com modelos de Machine Learning n\u00e3o temos de cara o valor dos nossos coeficientes como temos na regress\u00e3o. Para contornar isso utilizamos a t\u00e9cnica de SHAP, que por meio do shapley value, permite uma interpreta\u00e7\u00e3o do nosso modelo, retornando um coeficiente para cada feature.</p> <pre><code>library(fastshap)\nlibrary(shapviz)\n\ndados_treino1 &lt;- model$finalModel$data\nvars_model &lt;- model$finalModel$xNames\n\nshap &lt;- fastshap::explain(model$finalModel, exact = TRUE, new_data = model$finalModel$xNames)\n\nshap_plot &lt;- shapviz(object = shap, X = dados_treino1 %&gt;% select(all_of(vars_model)))\n\nsv_importance(shap_plot, max_display = 10,kind = \"bar\", fill = \"#ff7a00\") +\n  labs(title = \"SHAP Feature Importance\")\n</code></pre> <p>Al\u00e9m da import\u00e2ncia conseguimos tamb\u00e9m analisar o comportamento das features</p> <pre><code>sv_dependence(shap_plot, v = \"vl_last_atraso\")# feature \u00fanica\n\n#SHAP Beeswarm (Consist\u00eancia :: Sensibility &amp; Sanity)\nsv_importance(shap_plot, kind = \"beeswarm\", size = 0.5) +\n  labs(title = \"SHAP Beeswarm\")\n</code></pre> <p>Podemos analisar feature a feature com esse conjunto de 4 gr\u00e1ficos:</p> <pre><code>lucyR::feature_sanity()\n</code></pre> <p>ressaltando que para vari\u00e1veis cont\u00ednuas o scatterplot \u00e9 utilizado enquanto para vari\u00e1veis discretas utilizamos o boxplot</p>"},{"location":"A_modeling_guideline/modeling_guideline/#61-comparacao-de-modelos","title":"6.1 Compara\u00e7\u00e3o de modelos","text":"<p>Para comparar modelos, com objetivo inferencial, podemos utilizamos o BIC, que \u00e9 um crit\u00e9rio de sele\u00e7\u00e3o de modelos, que penaliza a verossimilhan\u00e7a pelo n\u00famero de par\u00e2metros do modelo proposto. Por\u00e9m em grande parte dos nosso problemas, queremos fazer previs\u00f5es, por esse motivo n\u00e3o o utilizamos.</p> <p>Bayes Factor \u00e9 uma op\u00e7\u00e3o de crit\u00e9rio</p>"},{"location":"A_modeling_guideline/modeling_guideline/#analise-de-drift","title":"An\u00e1lise de Drift","text":""},{"location":"A_modeling_guideline/modeling_guideline/#kl-divergence","title":"KL Divergence","text":"<p>Sens\u00edvel a pequenas mudan\u00e7as, especialmente probabilidades pr\u00f3ximas de zero, levando a grandes flutua\u00e7\u00f5es pois penaliza \u00e1reas com probabilidade baixa ou pr\u00f3xima de zero.</p> <p>Depende da sobreposi\u00e7\u00e3o entre distribui\u00e7\u00f5es, ou seja, \u00e0 medida que os dados de produ\u00e7\u00e3o se afastam dos dados de refer\u00eancia, a falta de sobreposi\u00e7\u00e3o aumenta a volatilidade da m\u00e9trica</p> <p>\u00c9 altamente responsiva a outliers, pois mudan\u00e7as nas caudas da distribui\u00e7\u00e3o podem levar a picos ou quedas repentinas nos valores, tornando-a mais inst\u00e1vel na presen\u00e7a de outliers</p>"},{"location":"A_modeling_guideline/modeling_guideline/#wasserstein","title":"Wasserstein","text":"<p>Mede o 'custo' cumulativo para transformar uma distribui\u00e7\u00e3o em outra, com foco nas dist\u00e2ncias entre massas de probabilidade. Essa abordagem permite um tratamento mais suave de pequenas flutua\u00e7\u00f5es, resultando em uma m\u00e9trica mais est\u00e1vel que o KL Divergence ao longo do tempo</p> <p>AA dist\u00e2ncia de Wasserstein \u00e9 independente de sobreposi\u00e7\u00e3o e pode lidar muito bem com mudan\u00e7as significativas de distribui\u00e7\u00e3o em forma ou localiza\u00e7\u00e3o</p>"},{"location":"A_modeling_guideline/modeling_guideline/#psi","title":"PSI","text":""},{"location":"A_modeling_guideline/modeling_guideline/#ks_1","title":"KS","text":""},{"location":"A_modeling_guideline/modeling_guideline/#7-grupos-homogeneos","title":"7 - Grupos Homog\u00eaneos","text":"<p>Com a modelagem finalizada, ou pelo menos uma V0, \u00e9 preciso agrupar seus resultados por grupos homog\u00eaneos (GHs). A ideia de criar grupos homog\u00eaneos \u00e9 observar o desempenho do modelo para cada grupo, ao inv\u00e9s de olhar o seu desempenho geral. Pode acontecer de no geral o modelo estar bem preditivo, por\u00e9m ao quebrar em grupos observamos que determinados grupos est\u00e3o subindo a m\u00e9dia de nossa preditividade, enquanto outros est\u00e3o pouqu\u00edssimo preditivos.</p> <p>Para a cria\u00e7\u00e3o dos GHs utilizamos a fun\u00e7\u00e3o <code>grupos_risco</code> do pacote <code>inter.ai</code>, que utiliza a fun\u00e7\u00e3o <code>classInt::classIntervals</code> para encontrar o melhor ponto de corte</p> <pre><code>inter.ai::gerar_grupos_homogeneos(y_true, y_pred, try_bins = 4:20)\n</code></pre> <p>\u00c9 preciso testar diferentes combina\u00e7\u00f5es de bins para encontrar a melhor parti\u00e7\u00e3o para os grupos homog\u00eaneos, uma vez que a altera\u00e7\u00e3o dos bins m\u00e1ximos e m\u00ednimos impacta na fun\u00e7\u00e3o.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#71-matriz-de-confusao","title":"7.1 - Matriz de confus\u00e3o","text":"<p>Podemos ao inv\u00e9s de comparar os modelos, pode ser o caso de termos modelos complementares, dessa forma a compara\u00e7\u00e3o se torna um pouco mais dif\u00edcil, como \u00e9 o exemplo da cria\u00e7\u00e3o de um modelo espec\u00edfico de fim de m\u00eas e outro para meio de m\u00eas. Nesse caso, se torna interessante avaliar o qu\u00e3o acert\u00edvo ambos os modelos s\u00e3o, para isso pegamos uma mesma base de dados (por exemplo a base do meio de m\u00eas) e fazemos uma matriz de confus\u00e3o para ambos, utilizando o melhor ponto de corte para ser utilizado para</p>"},{"location":"A_modeling_guideline/modeling_guideline/#teste-de-proporcao-com-correcao-de-bonferroni","title":"Teste de Propor\u00e7\u00e3o com corre\u00e7\u00e3o de Bonferroni","text":"<p>Ap\u00f3s agrupar sua base por GH, criando uma coluna com a soma do seu target e a quantidade de observa\u00e7\u00f5es por grupo, rodamos o teste de Bonferroni.</p> <pre><code>pairwise.prop.test(x=teste$soma_target,\n                   n=teste$N_grupo,\n                   p.adjust.method = \"bonferroni\",\n                   alternative = \"two.sided\",\n                   correct = FALSE)\n</code></pre> <p>O teste de propor\u00e7\u00e3o com ajuste de Bonferroni, feito pela fun\u00e7\u00e3o acima, multiplica o p-valor encontrado pelo n\u00famero de grupos, n\u00e3o sendo necess\u00e1rio utilizar a corre\u00e7\u00e3o de $\\frac{\\alpha}{m}$ manualmente para avaliar o p-valor, em que $H_0$ seria os grupos serem iguais, desse modo p-valor &lt; 0.05 significa n\u00e3o ter diferen\u00e7a significativa entre as compara\u00e7\u00f5es m\u00faltiplas.</p> <p>Vale ressaltar que o teste acima faz a compara\u00e7\u00e3o m\u00faltipla de todos os grupos, podendo estar superestimando os p-valores, para o caso de GHs \u00e9 interessante colocar o <code>p.adjust.method</code> como <code>none</code> e fazer a corre\u00e7\u00e3o manualmente multiplicando o p-valor pela quantidade de compara\u00e7\u00f5es (quantidade de grupos - 1) pois dessa forma teremos para a compara\u00e7\u00e3o de A, B, C e D apenas A -&gt; B, B -&gt; C, C -&gt; D.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#8-atualizacao-do-modelo","title":"8 - Atualiza\u00e7\u00e3o do Modelo","text":"<p>A ideia \u00e9 entregar um modelo r\u00e1pido, para podermos aprender com ele e gerar valor o mais r\u00e1pido poss\u00edvel. Ap\u00f3s a primeira entrega ser feita, n\u00e3o devemos nos contentar com os resultados, pelo contr\u00e1rio, como j\u00e1 temos uma entrega devemos buscar por melhorias no modelo que antes n\u00e3o eram poss\u00edveis devido a necessidade de tempo junto a necessidade da entrega.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#9-pontos-de-atencao-aos-resultados","title":"9 - Pontos de aten\u00e7\u00e3o aos resultados","text":"<p>Entender o qu\u00e3o preditivo est\u00e1 meu modelo. Acertar muito em p\u00fablicos \u00f3bvios e pouco em p\u00fablicos mais complexos com um ks de 90 \u00e9 pior do que acertar razo\u00e1vel em p\u00fablicos mais complexos e ks de 40</p> <p>Como medir objetivamente se a resposta do meu modelo est\u00e1 de fato agregando, al\u00e9m de olhar valor do KS?</p> <p>Comparar o modelo antigo (se existir) com o modelo novo, utilizando a mesma base para efeito de compara\u00e7\u00e3o</p> <p>Mudar a vis\u00e3o de sua modelagem pode ser uma sa\u00edda vi\u00e1vel, caso esteja estagnado em sua modelagem. Uma nova abordagem, como por exemplo modelar por contrato ao inv\u00e9s de cpf, buscar features de outros lugares, tentar uma r\u00e9gra de neg\u00f3cios ao inv\u00e9s de uma modelagem mais robusta, etc, podem ser boas alternativas.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#10-pos-modelagem","title":"10 - P\u00f3s modelagem","text":"<p>Com o modelo pronto o pr\u00f3ximo passo \u00e9 o deploy, que pode ocorrer de forma autom\u00e1tica ou manual, o \"manu\u00e1tico\" consiste em um c\u00f3digo com apenas o neces\u00e1rio para conseguir rodar o modelo manualmente de acordo com a demanda. Feito isso, existem algum caminhos a se seguir, seu modelo pode subir para produ\u00e7\u00e3o ou passar por uma experimenta\u00e7\u00e3o por exemplo. No caso do experimento pode ser necess\u00e1rio um direcionamento ao cliente para que seja feito de forma correta, evitando inconsist\u00eancias futuras.</p> <p>A <code>calibra\u00e7\u00e3o de modelo</code> consiste em um conjunto de an\u00e1lises, compostos por <code>Diagn\u00f3stico</code> e <code>Remedia\u00e7\u00e3o</code> para avaliar as probabilidades retornadas pelo modelo. O objetivo da calibra\u00e7\u00e3o do modelo \u00e9 garantir que as probabilidades de classe estimadas sejam consistentes com o que ocorreria naturalmente. (No caso de estimativas pontuais PODE fazer sentido essa abordagem, por\u00e9m ao criar os GHs temos uma mitiga\u00e7\u00e3o do erro a partir da predi\u00e7\u00e3o intervalar de cada grupo com bootstrap para avaliar o intervalo de 95%)</p>"},{"location":"A_modeling_guideline/modeling_guideline/#11-modelo-nao-supervisionado","title":"11 - Modelo n\u00e3o supervisionado","text":"<p>Para modelos n\u00e3o supervisionados n\u00e3o temos um target pr\u00e9-definido para podermos utilizar de insumo para nossa modelagem, dessa forma temos que utilizar de outras t\u00e9cnicas para chegarmos em resultados satisfat\u00f3rios.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#o-que-queremos-modelar","title":"O que queremos modelar?","text":""},{"location":"A_modeling_guideline/modeling_guideline/#e-possivel-obter-uma-proxy-do-que-esperamos-ao-final-da-modelagem","title":"\u00c9 poss\u00edvel obter uma proxy do que esperamos ao final da modelagem?","text":"<p>Esse \u00e9 um t\u00f3pico sens\u00edvel pois exige bastante conhecimento acerca de nosso problema, al\u00e9m de termos que nos atentar a vi\u00e9ses para nossa modelagem, caso tenhamos alguma ideia a priori do que fazer.</p> <p>Devemos seguir com o monitoramento afim de garantirmos a funcionalidade/efic\u00e1cia do mesmo. </p>"},{"location":"A_modeling_guideline/modeling_guideline/#12-algorithms","title":"12 - Algorithms","text":""},{"location":"A_modeling_guideline/modeling_guideline/#supervised","title":"Supervised","text":""},{"location":"A_modeling_guideline/modeling_guideline/#regressao","title":"Regress\u00e3o","text":""},{"location":"A_modeling_guideline/modeling_guideline/#regressao-linear","title":"Regress\u00e3o Linear","text":""},{"location":"A_modeling_guideline/modeling_guideline/#regressao-logistica","title":"Regress\u00e3o Logistica","text":""},{"location":"A_modeling_guideline/modeling_guideline/#cubist-regression","title":"Cubist Regression","text":"<p>Modelo de regress\u00e3o que utiliza recortes simples de \u00e1rvores de decis\u00e3o e cria modelos de regress\u00e3o dentro cada regra</p> <pre><code>Cubist::cubist(\n  x = X,\n  y = Y,\n  committees = 1, \n  control = cubistControl(\n    unbiased = FALSE,\n    rules = 100,\n    extrapolation = 100,\n    sample = 0,\n    seed = sample.int(4096, size = 1) - 1L,\n    label = \"outcome\"\n    )\n  )\n</code></pre>"},{"location":"A_modeling_guideline/modeling_guideline/#binomial","title":"Binomial","text":""},{"location":"A_modeling_guideline/modeling_guideline/#binomial-negativa","title":"Binomial Negativa","text":"<p>\u00c9 mais flex\u00edvel que a Poisson, pois possui um par\u00e2metro que ajusta a vari\u00e2ncia independentemente da m\u00e9dia.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#multinomial","title":"Multinomial","text":"<p>\u00c9 mais geral que a regress\u00e3o log\u00edstica porque a vari\u00e1vel dependente n\u00e3o est\u00e1 restrita a duas categorias, mas a um n\u00famero finito maior que 2 podendo ser ordinal ou n\u00e3o.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#poisson","title":"Poisson","text":"<p>\u00c9 um caso especial da distribui\u00e7\u00e3o binomial negativa. Assume m\u00e9dia e vari\u00e2ncias iguais (tal qual a regress\u00e3o assume dados normais)</p> <p>Tem como objetivo modelar contagens de eventos infinitos (Sem restri\u00e7\u00e3o para o n\u00famero m\u00e1ximo do target). Muitas vezes funciona com vari\u00e1veis cont\u00ednuas n\u00e3o negativas</p>"},{"location":"A_modeling_guideline/modeling_guideline/#regressao-quantilica","title":"Regress\u00e3o Quant\u00edlica","text":""},{"location":"A_modeling_guideline/modeling_guideline/#regressao-zoib-zero-one-inflated-beta","title":"Regress\u00e3o zoib (Zero-One-Inflated Beta)","text":""},{"location":"A_modeling_guideline/modeling_guideline/#generalized-additive-model-gam","title":"Generalized Additive Model (GAM)","text":""},{"location":"A_modeling_guideline/modeling_guideline/#decision-tree","title":"Decision Tree","text":"<p>\u00c1rvore de decis\u00e3o baseada em regras</p>"},{"location":"A_modeling_guideline/modeling_guideline/#random-forest-ensemble","title":"Random Forest (ensemble)","text":""},{"location":"A_modeling_guideline/modeling_guideline/#gradiente-boosted-regression-trees","title":"Gradiente Boosted Regression Trees","text":""},{"location":"A_modeling_guideline/modeling_guideline/#support-vector-machine","title":"Support Vector Machine","text":"<p>Geralmente utilizado em contextos de classifica\u00e7\u00e3o, encontra um hiperplano (podendo ser uma linha) para segregar categorias</p>"},{"location":"A_modeling_guideline/modeling_guideline/#naive-bayes","title":"Naive Bayes","text":""},{"location":"A_modeling_guideline/modeling_guideline/#xgboost","title":"XGBoost","text":""},{"location":"A_modeling_guideline/modeling_guideline/#lgbm","title":"Lgbm","text":""},{"location":"A_modeling_guideline/modeling_guideline/#catboost","title":"Catboost","text":""},{"location":"A_modeling_guideline/modeling_guideline/#adaboost","title":"AdaBoost","text":"<p>Ajusta o peso das amostras em cada itera\u00e7\u00e3o, as amostras mal classificadas recebem mais peso. O algoritmo foca em corrigir as amostras dif\u00edceis. O modelo final ser\u00e1 a combina\u00e7\u00e3o de classificadores fracos ponderados.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#gradient-boosting","title":"Gradient Boosting","text":"<p>Diferente do AdaBoosting, vai ajustar os erros residuais (diferen\u00e7a entre valor real e previs\u00e3o) em cada itera\u00e7\u00e3o. Cada modelo ir\u00e1 tentar prever e corrigir os erros das rodadas anteriores.</p> <p>Exemplo: O gradient come\u00e7a com uma previs\u00e3o simples de 180 mil para todas as casas e vai ajustando a cada itera\u00e7\u00e3o as previs\u00f5es, baseando na tentativa de descobrir o erro residual. A cada rodada o modelo vai ajustar os erros residuais. Na tabela abaixo o erro inicial de +20.000 na casa 1 foi ajustado para 10.000, resultando em uma nova previs\u00e3o de 190.000. O resultado final \u00e9 a soma das corre\u00e7\u00f5es feitas em cada rodada, aproximando-se do valor real</p> Casa Pre\u00e7o Real Predi\u00e7\u00e3o (Round1) Erro Residual (Round1) Previs\u00e3o Residual Nova Predi\u00e7\u00e3o 1 200.000 180.000 +20.000 +10.000 190.000 2 300.000 180.000 +120.000 +70.000 250.000 3 250.000 180.000 +70.000 +40.000 220.000"},{"location":"A_modeling_guideline/modeling_guideline/#rusboost","title":"RusBoost","text":""},{"location":"A_modeling_guideline/modeling_guideline/#bagging-bootstrap-aggregation","title":"Bagging (Bootstrap Aggregation)","text":"<p>Em caso de termos muitas vari\u00e1veis categ\u00f3ricas o Catboost \u00e9 utilizado, evitando ter que fazer diversas dummies para a modelagem</p>"},{"location":"A_modeling_guideline/modeling_guideline/#neural-network","title":"Neural Network","text":"<p>Se remover as camadas ocultas de uma rede neural ela se torna apenas um classificador linear simples, ou seja, pode lidar com tarefas diretas e linearmente separ\u00e1veis como AND e OR mas n\u00e3o pode lidar com XOR (OR exclusivo) que precisa de pelo menos uma camada oculta (junto da fun\u00e7\u00e3o de ativa\u00e7\u00e3o linear) para capturar seu padr\u00e3o n\u00e3o linear</p>"},{"location":"A_modeling_guideline/modeling_guideline/#recurrent-neural-network","title":"Recurrent Neural Network","text":""},{"location":"A_modeling_guideline/modeling_guideline/#convolutional-neural-network","title":"Convolutional Neural Network","text":""},{"location":"A_modeling_guideline/modeling_guideline/#graph-neural-network","title":"Graph Neural Network","text":""},{"location":"A_modeling_guideline/modeling_guideline/#unsupervised","title":"Unsupervised","text":""},{"location":"A_modeling_guideline/modeling_guideline/#hierarchical-clustering","title":"Hierarchical Clustering","text":""},{"location":"A_modeling_guideline/modeling_guideline/#k-clustering","title":"K- Clustering","text":""},{"location":"A_modeling_guideline/modeling_guideline/#k-means","title":"K-Means","text":""},{"location":"A_modeling_guideline/modeling_guideline/#k-median","title":"K-Median","text":""},{"location":"A_modeling_guideline/modeling_guideline/#k-modes","title":"K-Modes","text":""},{"location":"A_modeling_guideline/modeling_guideline/#mini-batch-k-means-clustering","title":"Mini Batch K-Means Clustering","text":""},{"location":"A_modeling_guideline/modeling_guideline/#fuzzy-k-modes","title":"Fuzzy K-Modes","text":"<p>\u00c9 uma extens\u00e3o do K-Modes, que ao inv\u00e9s de apontar cada objeto a um cluster, calcula o valor do grau de proximidade para cada objeto em cada cluster</p>"},{"location":"A_modeling_guideline/modeling_guideline/#fuzzy-c-means","title":"Fuzzy C-Means","text":"<p>\u00c9 uma vers\u00e3o probabilistica do K-Means. Associa todos os objetos em todos os clusters, sendo que a soma de todas as associa\u00e7\u00f5es \u00e9 1. Desse modo todos os clusters tem uma associa\u00e7\u00e3o cont\u00ednua (diferentemente do K-Means que \u00e9 discreta) com cada cluster em rela\u00e7\u00e3o a cada outro cluster</p> <p>O algoritmo atribui iterativamente e computa o centr\u00f3ide dos clusters igual ao K-Means at\u00e9 que qualquer fun\u00e7\u00e3o de crit\u00e9rio seja otimizada ou a converg\u00eancia caia abaixo de um threshold pr\u00e9-determinado.ld value.</p> <p>Esse algoritmo n\u00e3o \u00e9 rigoroso como o K-Means na atribui\u00e7\u00e3o e funciona bem para conjuntos de dados sobrepostos. No entanto, tem a mesma desvantagem que o K-Means de ter uma suposi\u00e7\u00e3o pr\u00e9via do n\u00famero de clusters. Al\u00e9m disso, um valor de threshold baixo fornece melhores resultados, mas \u00e9 mais caro do ponto de vista computacional.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#dbscan-clustering","title":"DBSCAN Clustering","text":""},{"location":"A_modeling_guideline/modeling_guideline/#gaussian-mixture-model-gmm","title":"Gaussian Mixture Model (GMM)","text":""},{"location":"A_modeling_guideline/modeling_guideline/#jenks","title":"Jenks","text":"<p>Jenks, Fisher e Fisher-Jenks</p>"},{"location":"A_modeling_guideline/modeling_guideline/#principal-component-analysis-pca","title":"Principal Component Analysis (PCA)","text":"<p>T\u00e9cnica de redu\u00e7\u00e3o de dimensionalidade</p>"},{"location":"A_modeling_guideline/modeling_guideline/#otimizacoes","title":"Otimiza\u00e7\u00f5es","text":"<p>Antes de definir qual abordagem utilizar faz-se necess\u00e1rio responder algumas perguntas:</p> <ul> <li>Seu problema tem uma fun\u00e7\u00e3o objetiva definida?</li> <li>Seu problema tem solu\u00e7\u00e3o linear?</li> <li>Seu problema tem um espa\u00e7o amostral convexo? (seu \u00f3timo local tamb\u00e9m \u00e9 global, ent\u00e3o encontrar uma solu\u00e7\u00e3o local \u00e9 suficiente)</li> </ul> <p>Respondidas as perguntas podemos optar por algoritmos de busca mais simples ou mais complexos, mas para essa decis\u00e3o pode ser interessante levar em considera\u00e7\u00e3o o Teorema de Bolzano-Weierstrass:</p> <p>A complexidade de uma problema de otimiza\u00e7\u00e3o est\u00e1 diretamente relacionado ao tamanho do Espa\u00e7o de Busca coorespondente. O processo de solu\u00e7\u00e3o de um problema pode ser reduzido a um Algoritmo de Busca Heur\u00edstica, cujo Espa\u00e7o de Busca \u00e9 formado por transforma\u00e7\u00f5es sucessivas de Estados em uma certa ordem de gera\u00e7\u00e3o e percurso, enquanto Algoritmos mais simples podem ir diretamente ao ponto \u00f3timo.</p> <p>Algoritmos heur\u00edsticos n\u00e3o garantem encontrar a solu\u00e7\u00e3o \u00f3tima, mas podem encontrar boas solu\u00e7\u00f5es em tempo menor (no caso de problemas mais complexos) e s\u00e3o extremamente \u00fateis quando o espa\u00e7o de busca \u00e9 grande ou a estrutura n\u00e3o \u00e9 bem definida.</p> <p>Podemos utilizar algoritmos heur\u00edsitocs quando:   - o espa\u00e7o de busca \u00e9 grande, tornando a busca simples impratic\u00e1vel - uma solu\u00e7\u00e3o aproximada ou sub\u00f3tima \u00e9 aceit\u00e1vel - os dados s\u00e3o complexos e din\u00e2micos</p>"},{"location":"A_modeling_guideline/modeling_guideline/#algoritmos-convexos","title":"Algoritmos Convexos","text":""},{"location":"A_modeling_guideline/modeling_guideline/#simplex","title":"Simplex","text":"<p>Se o seu problema tiver uma solu\u00e7\u00e3o linear, voc\u00ea pode usar o M\u00e9todo Simplex. Ele come\u00e7a na borda do poliedro das solu\u00e7\u00f5es vi\u00e1veis porque os v\u00e9rtices s\u00e3o candidatos a solu\u00e7\u00f5es \u00f3timas e permite uma explora\u00e7\u00e3o eficiente do espa\u00e7o de solu\u00e7\u00f5es usando a geometria dos problemas lineares. Isso se deve ao fato de que a solu\u00e7\u00e3o \u00f3tima de uma fun\u00e7\u00e3o linear, se existir, est\u00e1 em um v\u00e9rtice, j\u00e1 que fun\u00e7\u00f5es lineares atingem m\u00e1ximos ou m\u00ednimos nos extremos, uma vez que n\u00e3o tem curvatura para alcan\u00e7ar \u00f3timos no interior. Desta forma, o Simplex pode explorar os v\u00e9rtices sistematicamente sem computar todo o espa\u00e7o de solu\u00e7\u00f5es.</p>"},{"location":"A_modeling_guideline/modeling_guideline/#ordinary-least-squares-ols","title":"Ordinary Least Squares (OLS)","text":""},{"location":"A_modeling_guideline/modeling_guideline/#algoritmos-heuristicos","title":"Algoritmos Heur\u00edsticos","text":""},{"location":"A_modeling_guideline/modeling_guideline/#buscas-em-profundidade-limitada","title":"Buscas em profundidade limitada","text":""},{"location":"A_modeling_guideline/modeling_guideline/#simulated-annealing","title":"Simulated Annealing","text":""},{"location":"A_modeling_guideline/modeling_guideline/#genetic-algorithms","title":"Genetic Algorithms","text":""},{"location":"A_modeling_guideline/modeling_guideline/#12-model-monitoring","title":"12 - Model Monitoring","text":"<p>Quando temos um modelo em produ\u00e7\u00e3o, seja online ou em batch devemos fazer seu monitoramento afim de garantirmos a funcionalidade/efic\u00e1cia do mesmo. Podemos utilizar como material de consulta o <code>Working Paper No. 14</code></p>"},{"location":"A_modeling_guideline/modeling_guideline/#121","title":"12.1","text":"<p>O que?   - Consist\u00eancia no resultado do modelo Como?   - Taxa de aprova\u00e7\u00f5es est\u00e1vel, conversando com a taxa esperada do modelo</p>"},{"location":"A_modeling_guideline/modeling_guideline/#122","title":"12.2","text":"<p>O que?   - Comportamento dos grupos se manteve?   Como?   - Taxa de aprova\u00e7\u00f5es x taxa de bads dos GHs</p>"},{"location":"A_modeling_guideline/modeling_guideline/#123","title":"12.3","text":"<p>O que?   - Continuamos tratando da mesma popula\u00e7\u00e3o de quando treinamos?   Como?   - Observar o drift das features e seu descolocamento em fun\u00e7\u00e3o da m\u00e9dia</p>"},{"location":"A_modeling_guideline/modeling_guideline/#124","title":"12.4","text":"<p>O que?   - Avalia\u00e7\u00e3o da qualidade do ajuste do modelo. (O modelo ainda pode explicar os dados observados?) Como?   - Teste de Hosmer e Lemeshow para avaliar se as propor\u00e7\u00f5es observadas e esperadas s\u00e3o as mesmas ao longo da amostra</p>"},{"location":"A_modeling_guideline/modeling_guideline/#13-append","title":"13 - Append","text":""},{"location":"A_modeling_guideline/modeling_guideline/#mathematical-definitions-in-data-science","title":"Mathematical definitions in data science","text":""},{"location":"A_modeling_guideline/modeling_guideline/#gradient-descent","title":"Gradient Descent","text":"<p>$$\\theta_{j+1} = \\theta_{j} - \\alpha \\nabla J(\\theta_{j})$$ ### Normal Distribution</p> <p>$$f(x|\\mu,\\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}}exp(- \\frac{(x-\\mu)^2}{2\\sigma^2})$$</p>"},{"location":"A_modeling_guideline/modeling_guideline/#z-score","title":"Z-score","text":"<p>$$z = \\frac{x-\\mu}{\\sigma}$$</p>"},{"location":"A_modeling_guideline/modeling_guideline/#sigmoid","title":"Sigmoid","text":"<p>$$\\theta(x) = \\frac{1}{1+e^{-x}}$$</p>"},{"location":"A_modeling_guideline/modeling_guideline/#correlation","title":"Correlation","text":"<p>$$Correlation = \\frac{Cov(X,Y)}{Std(X) \\dot{} Std(Y)}$$</p>"},{"location":"A_modeling_guideline/modeling_guideline/#cosine-similarity","title":"Cosine Similarity","text":"<p>$$Similarity = \\frac{A \\dot{} B}{||A|| \\dot{} ||B||}$$</p> <p>Avi Chawla Save posts orrelation = \\frac{Cov(X,Y)}{Std(X) \\dot{} Std(Y)}$$</p>"},{"location":"A_modeling_guideline/modeling_guideline/#cosine-similarity_1","title":"Cosine Similarity","text":"<p>$$Similarity = \\frac{A \\dot{} B}{||A|| \\dot{} ||B||}$$</p> <p>Avi Chawla Save posts</p>"},{"location":"B_artifacts/canvas/","title":"Canvas","text":""},{"location":"B_artifacts/go_nogo/","title":"Go / no Go","text":""},{"location":"B_artifacts/work_instruction/","title":"Work Instruction","text":""},{"location":"C_patterns/data_preparation/","title":"Data Preparation","text":""},{"location":"D_statistical_concepts/correlation/","title":"Correlation","text":"<p>a</p>"},{"location":"D_statistical_concepts/homoscedasticity/","title":"Homoscedasticity","text":"<p>a</p>"},{"location":"D_statistical_concepts/outliers/","title":"Outliers","text":"<p>a</p>"},{"location":"D_statistical_concepts/seasonality/","title":"Seasonality","text":"<p>a</p>"},{"location":"D_statistical_concepts/trend/","title":"Trend","text":"<p>a</p>"},{"location":"D_statistical_concepts/volatility/","title":"Volatility","text":"<p>a</p>"},{"location":"E_glossary/bank_context/bnpl/","title":"BNPL","text":"<p>a</p>"},{"location":"E_glossary/bank_context/csi/","title":"CSI","text":"<p>b</p>"},{"location":"E_glossary/bank_context/npl/","title":"NPL","text":"<p>c</p>"},{"location":"E_glossary/bank_context/pdd/","title":"PDD","text":""},{"location":"E_glossary/bank_context/pdd/#pddmargem","title":"PDD/Margem","text":""},{"location":"E_glossary/bank_context/roi/","title":"ROI","text":""},{"location":"E_glossary/bank_context/sla/","title":"SLA","text":""},{"location":"E_glossary/bank_context/tpv/","title":"TPV","text":""},{"location":"F_models/models/","title":"A","text":"<p>Benchmark with different models in the world</p>"},{"location":"F_models/models/#bank-context","title":"Bank Context","text":""},{"location":"F_models/models/#application-models","title":"Application Models","text":""},{"location":"F_models/models/#collection-models","title":"Collection Models","text":""},{"location":"F_models/application/onboarding_pj/","title":"Onboarding PJ","text":""},{"location":"F_models/behavior/behavior/","title":"Behavior","text":""},{"location":"F_models/collection/creli/","title":"Creli","text":""},{"location":"G_study_notes/study_notes/","title":"Study Notes","text":""},{"location":"H_links/links/","title":"Links","text":""},{"location":"I_articles/articles/","title":"Articles","text":""},{"location":"J_references/references/","title":"References","text":""}]}